\subsubsection{Header}
\begin{lstlisting}

	#ifndef NARXNET_H
	#define NARXNET_H 1


	#include "fann.h"
	#include <stdlib.h>


	#if		__cplusplus
	#define NARX_C_API extern "C"
	#else
	#define NARX_C_API
	#endif

	typedef fann*			net_p;
	typedef fann_type		float_t;
	typedef float_t*		float_p;
	typedef unsigned long	offset_t;
	typedef unsigned long 	flag_t;



	/// @section	NARX_OPT_x
	/// @brief		Exposed global options
	/// @{
	#ifndef NARX_OPT_COMPUTE_MSE
	#define NARX_OPT_COMPUTE_MSE		1	///< MSE is computed on each training iteration
	#endif
	#ifndef NARX_OPT_USEFANN_MSE
	#define NARX_OPT_USEFANN_MSE		0	///< MSE is drawn from internal FANN network (@todo ... something's wrong with it? or me?)
	#endif
	/// @}



	/// @brief	Standard NARX network setup structure.
	///			For proper network config, all available fields must be set before NARXNet_Create(...) is called.
	typedef struct NARXConfig
	{
		offset_t	input_len;			///< length of a unit-input block, [O]
		offset_t	output_len;			///< length of a unit-output block, [U]
		offset_t	order;				///< number of delay input-layer delays
		offset_t	n_hidden_layers;	///< Strictly : {1 or 2}
		offset_t	hidden_len_1;		///< Length of first hidden layer
		offset_t	hidden_len_2;		///< Length of first hidden layer

		float_t		weight_init;		///< Defines value range of weights on init
		float_t		learning_rate_init;	///< Defines learning rate on init
		float_t		momentum_init;		///< Defines learning momentum on init
	} NARXConfig_t;



	typedef struct NARXNet
	{
		net_p		network;			///< Base Feedforward Neural Network (fann impl)

		offset_t	network_order;
		offset_t	output_block_len;
		offset_t	input_block_len;
		offset_t	output_offset;
		offset_t	input_offset;

		offset_t	output_buffer_len;	///< LEN = (output_len)					
		offset_t	input_buffer_len;	///< LEN = (output_len+input_len)*order

		float_p		output_buffer;		///< [\hat{O}_{k}]
		float_p		output_buffer_prev;	///< [\hat{O}_{k-1}]
		float_p		output_buffer_diff;	///< [\del\hat{O}_{k-1}]

		float_p		input_buffer;		///< [O_{k-1},U_{k-1},...,O_{k-N},U_{k-N}]
		float_t		MSE;
		float_t		MSE_prev;
	} NARXNet_t;



	/// @brief	Used to define the NARX architecture (routing) option
	///			The NARXNet option allows for switchin between parallel and series-parallel
	///			Architectures on the fly.
	typedef enum NARXMode
	{
		NARX_PARALLEL,
		NARX_SERIES_PARALLEL,
	} NARXMode_t;


	typedef enum NARXOpt
	{
		NARX_LR_ADAPTIVE_PROP	= 0x01,	///< MSE-proportional LR adaptation
		NARX_LR_ADAPTIVE_BOLD	= 0x02,	///< Bold-driver(-like) LR adaptation
		NARX_TRAIN				= 0x04,	///< Training on update active
		NARX_PREDICT			= 0x08	///< Prediction on update active
	} NARXOpt_t;




	NARX_C_API void NARXNet_Create ( NARXNet_t* net, NARXConfig_t*	conf );
	NARX_C_API void NARXNet_Destroy( NARXNet_t* net );
	NARX_C_API void NARXNet_Update(
		NARXNet_t*			net,
		const float_p		training_signal,
		const float_p		new_input,
		const NARXMode_t	mode,
		const flag_t		opts
	);


	NARX_C_API const float_p NARXNet_GetPrediction( NARXNet* net );

	#if NARX_OPT_COMPUTE_MSE
	NARX_C_API const float_t NARXNet_GetMSE( NARXNet_t* net );
	NARX_C_API void NARXNet_ResetMSE( NARXNet_t* net  );
	#endif


	#endif
\end{lstlisting}


\subsubsection{Implementation}
\begin{lstlisting}

	#include "NARXNet.h"
	/// @todo Extend to a cascade network option
	/// @todo Extend to a space network option


	/// @section NARX_GLOBAL_x
	/// @brief	Fixed, global definitions. Change at your own risk.
	/// @{
	#define NARX_GLOBAL_TRAINING_ALGORITHM			FANN_TRAIN_INCREMENTAL
	#define NARX_GLOBAL_ERROR_FUNCTION				FANN_ERRORFUNC_TANH
	#define NARX_GLOBAL_HIDDEN_ACTIVATION_FUNCTION	FANN_SIGMOID_SYMMETRIC
	#define NARX_GLOBAL_OUTPUT_ACTIVATION_FUNCTION	FANN_LINEAR
	#define NARX_BOLD_LAMBDA						0.0001f
	#define NARX_BOLD_PENALTY						0.0002f
	#define NARX_PROP_LAMBDA						0.1f
	#define NARX_MSE_LP_GAIN						0.01f
	#define	NARX_MSE_FAIL							10
	#define NARX_MIN_LEARNING_RATE					1e-8f
	#define NARX_MAX_LEARNING_RATE					1e-2f
	/// @}



	/// @brief	Shifts entire blocks within a sequential buffer and inserts a new item 
	///	@todo	Add to vector library (im not even sure which one is most recent at this point)
	///	@param	buffer		a sequential buffer of inline blocks of length 'block_len'
	/// @param	item		a new item to add to the buffer of length 'block_len'
	/// @param	offset		offset of targeted input set
	/// @param	block_len	the length of a single block
	///	@param	n_blocks	number of blocks in the buffer
	static void tapped_input_buffer_insert( float_p buffer, float_p item, const offset_t offset, const offset_t block_len, const offset_t n_blocks )
	{

		unsigned int idx;

		/// Get swap stop-position
		unsigned int len_end = (n_blocks-1UL)*block_len;
		
		/// Start buffer at input offset
		buffer+=offset;

		/// Copy blocks back
		for( idx = 0UL; idx < len_end; idx++ )
		{
			buffer[idx] = buffer[idx+block_len];	
		}

		/// Insert new item
		memcpy((buffer+len_end),item,block_len*sizeof(float_t));
	}



	static void scale_up( float_p buffer, float_p scale_value, offset_t len )
	{
		while(len--)
			*(buffer+len)*=(*scale_value);
	}


	static void scale_down( float_p buffer, float_p scale_value, offset_t len )
	{
		while(len--)
			*(buffer+len)/=(*scale_value);
	}


	static void diff( float_p dst, float_p src1, float_p src2, offset_t len )
	{
		while(len--)
			*(dst+len) = *(src2+len) - *(src1+len);
	}


	#if NARX_OPT_COMPUTE_MSE
	const float_t NARXNet_GetMSE( NARXNet_t* net )
	{
		return net->MSE;
	}
	#endif


	const float_p NARXNet_GetPrediction( NARXNet* net )
	{
		return net->output_buffer;
	}


	void NARXNet_Create( 
		NARXNet_t*		net, 
		NARXConfig_t*	conf
	){
		/// Compute Necessary Input Buffer Length
		net->input_buffer_len	= ( (conf->input_len+conf->output_len) * conf->order );
		
		/// Input-buffer Positional Information
		net->network_order		= conf->order;
		net->input_block_len	= conf->input_len;
		net->output_block_len	= conf->output_len;
		net->input_offset		= (0UL);
		net->output_offset		= (conf->input_len*conf->order);

		/// Compute Necessary Output Buffer Length
		net->output_buffer_len	= conf->output_len;
		
		/// Allocate Input Buffer + copy swap
		net->input_buffer		= (float_p)calloc( net->input_buffer_len,	sizeof(float_t) );

		/// Allocate Output Buffer + copy swap
		net->output_buffer		= (float_p)calloc( net->output_buffer_len,	sizeof(float_t) );
		net->output_buffer_prev	= (float_p)calloc( net->output_buffer_len,	sizeof(float_t) );
		net->output_buffer_diff	= (float_p)calloc( net->output_buffer_len,	sizeof(float_t) );

		/// Create Base-FFNN
		if(conf->n_hidden_layers==2UL)
			net->network = fann_create_standard(2UL+conf->n_hidden_layers,net->input_buffer_len,conf->hidden_len_1,conf->hidden_len_2,net->output_buffer_len);
		else
			net->network = fann_create_standard(2UL+conf->n_hidden_layers,net->input_buffer_len,conf->hidden_len_1,net->output_buffer_len);
		
		/// Setup the Base-FFNN
		fann_randomize_weights				(net->network,-conf->weight_init,+conf->weight_init);
		fann_set_learning_momentum			(net->network, conf->momentum_init);
		fann_set_learning_rate				(net->network, conf->learning_rate_init);

		/// Fixed Global Configs (@see NARX_GLOBAL_x) 
		fann_set_training_algorithm			(net->network, NARX_GLOBAL_TRAINING_ALGORITHM);
		fann_set_activation_function_hidden	(net->network, NARX_GLOBAL_HIDDEN_ACTIVATION_FUNCTION);
		fann_set_activation_function_output	(net->network, NARX_GLOBAL_OUTPUT_ACTIVATION_FUNCTION);
		fann_set_train_error_function		(net->network, NARX_GLOBAL_ERROR_FUNCTION);

	#if NARX_OPT_COMPUTE_MSE
	#if NARX_OPT_USEFANN_MSE
		/// Reset the MSE value
		fann_reset_MSE						( net->network );
	#endif
	#endif
		net->MSE = net->MSE_prev = 0.f;
	}



	void NARXNet_Destroy( 
		NARXNet_t*		net
	){
		/// Deallocate Input Buffers
		free(net->input_buffer);
		
		/// Deallocate Output Buffers
		free(net->output_buffer);
		free(net->output_buffer_diff);
		free(net->output_buffer_prev);

		/// Deallocate Base-FFNN
		fann_destroy(net->network);
	}



	static void s_NARXNet_Predict( NARXNet_t* net, offset_t setmem )
	{
	#ifdef NARX_MSE_FAIL
		if( net->MSE > NARX_MSE_FAIL )
			abort();
	#endif

		/// Store back old output
		memcpy( net->output_buffer_prev, net->network->output, sizeof(float_t)*net->output_block_len );


		/// Run Network Predictions
		float_p ptr = fann_run( net->network, net->input_buffer );


		if( setmem )
		{
			/// We need a copy of the output to prevent data corruption caused by changes in the underlying fann mem.
			memcpy( net->output_buffer, ptr, sizeof(float_t)*net->output_block_len );

			/// Get diff
			diff( net->output_buffer_diff, net->output_buffer_prev, net->output_buffer, net->output_block_len );
		}
	}


	#if !NARX_OPT_USEFANN_MSE
	static void s_NARXNet_UpdateSelfMSE( NARXNet_t* net, float_p train_signal )
	{
		unsigned int idx;
		float_t	MSE_km1 = net->MSE;
		net->MSE = 0.f;
		for( idx = 0; idx < net->output_block_len; idx++ )
			net->MSE += powf(net->network->output[idx]-train_signal[idx],2.f);

		/// LPF MSE
		net->MSE = (NARX_MSE_LP_GAIN)*net->MSE + (1.0f-NARX_MSE_LP_GAIN)*MSE_km1;
	}

	void NARXNet_ResetMSE( NARXNet_t* net )
	{
		fann_reset_MSE( net->network );
	}
	#endif


	static void s_NARXNet_Train( NARXNet_t* net, float_p train_signal )
	{
		net->MSE_prev = net->MSE;

	#if NARX_OPT_COMPUTE_MSE
	#if NARX_OPT_USEFANN_MSE
		/// Get interal MSE
		net->MSE = net->network->MSE_value;
	#else
		/// Update NARX MSE from training signal and known output
		s_NARXNet_UpdateSelfMSE(net,train_signal);
	#endif
	#endif

		//if( (net->MSE - net->MSE_prev) > 0.001f )
		/// Run training routine on current input set for last output
		fann_train( net->network, net->input_buffer, train_signal );
	}



	static void s_NARX_LR_Adapt(NARXNet_t*	net, const flag_t opts)
	{
		if(opts&NARX_LR_ADAPTIVE_BOLD)
		{
			if( net->MSE > net->MSE_prev )
				net->network->learning_rate *= (1.f - NARX_BOLD_PENALTY - NARX_BOLD_LAMBDA);
			else
				net->network->learning_rate *= (1.f + NARX_BOLD_LAMBDA);

			if(net->network->learning_rate < NARX_MIN_LEARNING_RATE )
				net->network->learning_rate = NARX_MIN_LEARNING_RATE;
			else
			if(net->network->learning_rate > NARX_MAX_LEARNING_RATE )
				net->network->learning_rate = NARX_MAX_LEARNING_RATE;
		}
		else
		if(opts&NARX_LR_ADAPTIVE_PROP)
		{
			net->network->learning_rate = NARX_PROP_LAMBDA*expf(-net->MSE*NARX_PROP_LAMBDA);
		}
	}


	void NARXNet_Update(
		NARXNet_t*			net,
		const float_p		training_signal,
		const float_p		new_input,
		const NARXMode_t	mode,
		const flag_t		opts
	)
	{

		/// Train network with current training signal and last input buffer
		if(opts&NARX_TRAIN)
			s_NARXNet_Train(net,training_signal);


		/// Adapt LR
		s_NARX_LR_Adapt(net,opts);


		/// Add known output to input buffer (parallel mode)
		if(mode==NARX_SERIES_PARALLEL)
			tapped_input_buffer_insert( net->input_buffer, training_signal, net->output_offset, net->output_block_len, net->network_order );
		/// Add self output to input buffer (series-parallel mode)
		/// * here we are using the raw output of the base-FFNN, which we are trying to avoid, but we need a universally unscaled
		/// * version of the output for routing. This is the best option to satisfy both the scaled and unscaled modes.
		else/// NARX_PARALLEL
			tapped_input_buffer_insert( net->input_buffer, net->network->output, net->output_offset, net->output_block_len, net->network_order );


		/// Add known input to the input buffer (both modes)
		tapped_input_buffer_insert( net->input_buffer, new_input, net->input_offset, net->input_block_len, net->network_order );


		/// Update prediction
		s_NARXNet_Predict(net,(opts&NARX_PREDICT));
	}

\end{lstlisting}
